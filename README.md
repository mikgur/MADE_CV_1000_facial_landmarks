# 1000 Facial Landmarks

## Kaggle PL result: 8.92453

![Leaderboard](https://i.ibb.co/1qRN9Px/made-cv-kaggle-screenshot.png)

## Описание лучшего решения:

Структура скрипта сохранена от baselin'а

- Архитектура сети - resnet50
- initial lr = 3e-4
- optimizer - AdamW
- lr_scheduler - ReduceLROnPlateau
- 40 эпох
- Аугментация данных:
    - Удаление черной рамки
    - Вырезаем из центра изображения квадрат 224х224 (с соответствующим масштабированием при необходимости)
    - Отражение от вертикальной оси с вероятностью 50%
    - Поворот на произвольный угол
    - Изменения яркости/контраста
    - Нормализация с параметрами imagenet

## Запуск
Аналогично baselin'у из командной строки

## Дневник эксперимента

Успел попробовать довольно много разных идей, опишу их сгруппировав по типам:

#### Аугментации:
- увеличение разрешения изображений (от 128х128 до 224х224) - _это дало существенный эффект, жаль решил попробовать 224х224 в самом конце_

- горизонтальный флип - _помогло избежать переобучения_
- поворот вокруг центра - _помогло избежать переобучения_
- изменял аспект изображений (вырезал не квадрат, а прямоугольник 166x128), чтобы он был больше похож по аспекту на лицо и было меньше обрезаний подбородка/лба - _в итоге ушел от этого, так как роста качества не произошло_
- яркость/контрастность
- удаление черной рамки вокруг изображений
- определил “угол поворота головы”, с использование PCA и scipy.spatial.procrustes - _это ничего не дало, поэтому в финальную версию не включил_
- Нашел примеры (от 3 до 15 тысяч) с кривой разметкой - исключил их - _качество на тесте упало - поэтому в итоге отказался от очистки данных_

#### Архитектуры:
- Resnet 18/34/50/101 - _до 50 заметный рост качества, потом практически нет, поэтому итоговая модель 50_
- Resnext
- Inceptionv4
- самописный [Denseunet](https://arxiv.org/pdf/1709.07330.pdf)

#### Метрики:
- MSE с поправкой на сжатие/растяжение - чтобы была похожа на метрику на kaggle

####  Loss-функции
- mse - вообще не понравилось
- mae - зашло лучше всего
- smooth_l1 - по логике должно было быть еще лучше, но нет
- wing_loss - https://arxiv.org/abs/1711.06753
- adaptive wing_loss - для heatmap regression - https://arxiv.org/abs/1904.07399 - вот тут как раз попробовал самописный densenet из https://arxiv.org/pdf/1709.07330.pdf - в статье  https://arxiv.org/pdf/1908.01070.pdf нашел что для heatmap regression такая архитектура хорошо подходит - _очень медленно обучалась, при этом не могу сказать что качество было сильно лучше чем у mae_

#### Оптимизатор:
- AdamW с decreaseOnPlateu
- пробовал еще OneCycle - тоже не плохо, но особого прироста не заметил

#### Режимы обучения:
обучал только FC
обучал по кускам resnet - по 5 частям по сути
обучал разные части с разными lr
в итоге самое лучшее качество там, где обучалась вся модель - видимо потому что достаточно большой датасет

#### Ensembling
Попробовал пару раз для разных моделей - качество не улучшилось, попробовать более интенсивно не успел